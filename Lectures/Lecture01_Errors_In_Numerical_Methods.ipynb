{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLIAtsF0/u2d7OGQvkosmX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidrezanorouzi/numericalMethods/blob/main/Lectures/Lecture01_Errors_In_Numerical_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Errors in Numerical Methods**\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Lecturer: **Hamidreza Norouzi**\n",
        "\n",
        "&nbsp;"
      ],
      "metadata": {
        "id": "zKCFK_wccRQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Notes**‚ùï\n",
        "This content forms a part of the instructional presentations for the **`numerical methods in chemical engineering`** course designed for undergraduate chemical engineering students at Amirkabir University of Technology.\n",
        "\n",
        "Feel free to utilize the information and source codes provided in this material, ensuring appropriate acknowledgment of the original document.\n",
        "\n",
        "The visual elements featured in this document are either original or have been obtained from the following sources, unless specified otherwise:\n",
        "\n",
        "* Steven C. Chapra, Applied Numerical Methods with Matlab for Engineers and Scientists, 3rd edition, McGraw-Hill (2012).\n",
        "* Amos Gilat and Vish Subramanian, Numerical Methods for Engineers and Scientists, 3rd edition, Wiley (2014).\n",
        "\n",
        "<div align=\"center\">\n",
        "üü™ üü™ üü™\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sfFhUVkMkDXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  üîµ 1) Why do we use numerical methods in chemical engineering?\n",
        "\n",
        "We always deal with mathematical equations in real-world engineering problems:\n",
        "*   We describe physical phenomena using mathematical equations\n",
        "*   We use mathematical equations to relate physical properties to state variables (Temperature, pressure, etc.)\n",
        "*   We deal with measured data and we need to perform data reduction (finding a mathematical relation between variables) or directly use them in engineering computations\n",
        "\n",
        "To solve an engineering problem, a bunch of mathematical equations are present. we always need numerical methods and computers to solve the equations and perform the required calculations.  \n",
        "\n",
        "<div align=\"center\">\n",
        "üü¶ üü¶ üü¶\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cUgOnjysiVG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü¢ 2) Numerical methods and quantifying errors\n",
        "## 2-1) True error\n",
        "* A Numerical method employs **approximations** to represent an equation or to  calculate the exact quantities.\n",
        "* Therefore, we are always some deviations from exact solution, called **error**. So, we always have:\n",
        "$$\n",
        "trueValue = approximation + error  \\tag{1}\n",
        "$$\n",
        "\n",
        "* Rearranging the above equation will give **true error**:\n",
        "$$\n",
        "E_{t} = trueValue - approximation \\tag{2}\n",
        "$$\n",
        "\n",
        "* Eq. (2) does not reflect the magnitude of the numbers. So we use relative errors, usually expressed in precent, **true percent relative error**:\n",
        "$$\n",
        "œµ_{t}=\\frac{trueValue-approximation}{trueValue} * 100\\% \\tag{3}\n",
        "$$\n",
        "note that we always use the **absolute** of the above value as error.\n",
        "\n",
        "&nbsp;\n",
        "\n"
      ],
      "metadata": {
        "id": "HpFkDel3lzrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùì **Example 1:**\n",
        "Compute the true error and true percent relative error in the following measurements:\n",
        "\n",
        "(A) A pen: true length = 10 cm, measured length = 11 cm\n",
        "\n",
        "(B) A pipe: true length = 1000 cm, measured length = 1001 cm\n",
        "\n",
        "### üí° *solution*\n",
        "\n",
        "(A)\n",
        "\n",
        "$$\n",
        "E_{t}= |11 - 10| = 1 \\ cm \\\\\n",
        "œµ_{t}=|\\frac{10-11}{10}|*100\\% = 10\\%\n",
        "$$\n",
        "(B)\n",
        "$$\n",
        "E_{t}= |1000 - 1001| = 1 \\ cm \\\\\n",
        "œµ_{t}=|\\frac{1000-1001}{1000}|*100\\% = 0.1\\%\n",
        "$$"
      ],
      "metadata": {
        "id": "bkqlZfxdNLcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-2) Approximate error\n",
        "* In numerical methods, we usually have approximation error instead of true error. So, we define the approximation error as:\n",
        "$$\n",
        "œµ_{a}=\\frac{approximation \\ error}{approximation} √ó 100\\% \\tag{4}\n",
        "$$\n",
        "\n",
        "* and in iterative methods, we rewrite the equation as:\n",
        "$$\n",
        "œµ_{a}=\\frac{present \\ approximation - previous \\ approximation}{present \\ approximation} √ó 100\\% \\tag{5}\n",
        "$$"
      ],
      "metadata": {
        "id": "bhgGNszSh1oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùì **Example 2:**\n",
        "Approximate the exponential function at x = 0.5 using McLaurin\n",
        "series. The approximated value should have 0.05% precision.\n",
        "$$\n",
        "e^x = 1+x+\\frac{x^2}{2!}+\\frac{x^3}{3!}+...+\\frac{x^n}{n!}\n",
        "$$\n",
        "\n",
        "### üí° *solution*\n",
        "We stop adding terms from McLaurin series when the relative precent approximate error is less than 0.05%."
      ],
      "metadata": {
        "id": "VVsa7Nrdpnhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = 0.5\n",
        "term = 1\n",
        "app = term\n",
        "prevApp = app\n",
        "trueValue = np.exp(x)\n",
        "\n",
        "print(\"%7s|%14s|%14s|%14s\" %(\"Terms\",\"Approxiamte\",\"true Error (%)\",\"App. Error (%)\"))\n",
        "\n",
        "for i in range(1,30):\n",
        "  term *= x/(i)\n",
        "  app += term\n",
        "  ep = np.abs(trueValue-app)/trueValue*100\n",
        "  eApp = np.abs(prevApp-app)/app*100\n",
        "  prevApp = app\n",
        "  print(\"%7d|%14.6f|%14.6f|%14.6f\" %(i+1, app, ep, eApp) )\n",
        "  if eApp<0.05:\n",
        "    break"
      ],
      "metadata": {
        "id": "DZ7slj9Zlwh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65a765e-7a72-4670-cea2-f23394c863d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Terms|   Approxiamte|true Error (%)|App. Error (%)\n",
            "      2|      1.500000|      9.020401|     33.333333\n",
            "      3|      1.625000|      1.438768|      7.692308\n",
            "      4|      1.645833|      0.175162|      1.265823\n",
            "      5|      1.648438|      0.017212|      0.157978\n",
            "      6|      1.648698|      0.001416|      0.015795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align =\"center\">\n",
        "üü©üü©üü©\n",
        "</div>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hTdgZHEGl-uV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü£ 3) Representation of numbers in computers\n",
        "## 3-1) Integer numbers  \n",
        "* Numbers are stored in the memory of the computer in binary (base 2) form.\n",
        "* Each binary digit (may contain 0 or 1) is called a bit.\n",
        "* An integer number with base 10 is first converted to base 2 and then are stored in the bits of memory with zeros and ones.\n",
        "* For example 173 in base-10 can be represented in binary:\n",
        "$$\n",
        "(10101101)_{2} = 1\\times 2^7 + 0\\times2^6 + 1\\times 2^5 + 0 \\times2^4 + 1\\times2^3 + 1\\times2^2 + 0 \\times 2^1 + 1 \\times 2^0 = (173)_{10}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "y8EOE1vSFfbW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3W-LDoRZbfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0715c8-496b-470c-bc3c-dcb62152bc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decimal: 173 ==> binray: 0b10101101\n",
            "decimal: -173 ==> binray: -0b10101101\n",
            "decimal: 65536 ==> binray: 0b10000000000000000\n",
            "decimal: 4294967296 ==> binray: 0b100000000000000000000000000000000\n",
            "type of variable c is <class 'int'>\n"
          ]
        }
      ],
      "source": [
        "a: int = 173\n",
        "b = pow(2,16)\n",
        "c = pow(2,32)\n",
        "\n",
        "print(f'decimal: {a} ==> binray: {bin(a)}')\n",
        "print(f'decimal: {-a} ==> binray: {bin(-a)}')\n",
        "print(f'decimal: {b} ==> binray: {bin(b)}')\n",
        "print(f'decimal: {c} ==> binray: {bin(c)}')\n",
        "print(f'type of variable c is {type(c)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In python, the length of integer numbers (number of bits dedicated to it) is unlimited. So, we can store very large integers in memory.\n",
        "* In other languages like, C, C++ and Fortran, we need to specify the length of integer number. For example in C++, we may use 8 (`char`), 16 (`short`), 32 (`int`)or 64 (`long int`) bits for integer numbers."
      ],
      "metadata": {
        "id": "VBpOC0ZCp6PX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-2) Floating point numbers\n",
        "* Large and small floating-point numbers can be represented using decimal notation (also called scientific notation):\n",
        "$$\n",
        "d.dddddd \\times10^p \\tag{6}\n",
        "$$\n",
        "* The digits to the left of decimal point are called **mantissa** and represent the number of significant digits.\n",
        "$$ 0.dddddd $$\n",
        "* For example:\n",
        " * $0.000193$ is represented as $1.93 \\times 10^{-5}$: it has two significant digits and is of order of $O(10^{-6})$\n",
        " * $6543.743$ is represented as $6.543743\\times10^{3}$: it has six significant digits and is of order of $O(10^4)$.\n",
        "\n",
        "* If we had bits that could store numbers 0 to 9, then the decimal representation of the number could be used for storing numbers in computer memory.\n",
        "* For $6.543743\\times10^{3}$ the mantissa is $0.543743$ and it can be written as\n",
        " $$5\\times10^{-1}+4\\times10^{-2}+3\\times10^{-3}+7\\times10^{-4}+4\\times10^{-5}+3\\times10^{-6} = 0.543743$$\n"
      ],
      "metadata": {
        "id": "dOo5n1FQQWnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Computer memory can store binary numbers, so the floating point numbers should be expressed in terms of zeros and ones:\n",
        "$$\n",
        "1.bbbbbb\\times2^{bbb} \\tag{7}\n",
        "$$\n",
        "where $1.bbbbbb$ is **mantissa** and $bbb$ is **exponent**.\n",
        "\n",
        "* For example:\n",
        "$$\n",
        "(0.3125)_{10} = \\frac{0.3125}{2^{-2}}\\times{2^{-2}} = 1.25\\times2^{-2} = (1.01\\times2^{-10})_{2} \\\\\n",
        "\\text{where    } (0.25)_{10} = 0\\times2^{-1}+1\\times2^{-2}\n",
        "$$"
      ],
      "metadata": {
        "id": "Vfhm4Drh0C4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-3) How to store floating point numbers in computer memory?\n",
        "* In computer memory the floating-point numbers are stored in bits based on the IEEE-754 standard (1985).\n",
        " * Single precision uses 32 bits\n",
        " * Double precision uses 64 bits\n",
        "* **Single precision (32 bit)**\n",
        " * The first bit is for sign\n",
        " * The next 8 bits is for exponent\n",
        " * The rest of 23 bits for mantissa\n",
        " * Remember our last example, the binary representation of 0.3125:\n",
        " $$(0.3125)_{10} = (1.01\\times2^{-10})_{2} \\\\\n",
        "  0-01111101-01000000000000000000000$$\n",
        "  You can test the decimal to binary conversion using this [online tool](https://www.h-schmidt.net/FloatConverter/IEEE754.html). Note that the exponent is added to a bias 127.\n",
        "\n",
        "* **Double precision (64 bit)**\n",
        " * The first bit is for sign\n",
        " * The next 11 bits for exponent\n",
        " * The rest of 52 bits for mantissa"
      ],
      "metadata": {
        "id": "cndzfUDw8VrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-4) Properties of double precision\n",
        "* Floating point number in python is double precision type and is called `float`\n",
        "* The smallest exponent with 11 digits is -1023 and the largest expoenent is 1024\n",
        "* The smallest positive number is:\n",
        "$$ 2^{-1022} = 2.2\\times10^{-308} $$\n",
        "  any positive value smaller than this cannot be stored in the computer memory and when this occurs, it is called **underflow**.\n",
        "* The largest positive number is:\n",
        "$$\n",
        "2^{1024} = 1.8\\times10^{308}\n",
        "$$\n",
        "any number larger than this cannot be stored in the memory and when this occurs, it is called **overflow**."
      ],
      "metadata": {
        "id": "LJdnb-mGCC1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=15xwZjnhJSg0JTv7DgovO_4sTCPSz2pBc\" width=\"600\" />\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "iZaOPCmIFx4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"largest positive floating point (double)\", sys.float_info.max)\n",
        "print(\"smallest positive floating point (double)\", sys.float_info.min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saEbSwFt8bl9",
        "outputId": "b75c5af9-c8d0-4946-d13f-d2b9bacb343b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "largest positive floating point (double) 1.7976931348623157e+308\n",
            "smallest positive floating point (double) 2.2250738585072014e-308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The precision of the float number is defined as the smallest value of mantissa that can be stored:\n",
        "$$\n",
        "2^{-52} = 2.22\\times10^{-16}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "6JwRPAJrNJLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"epsilon = \", sys.float_info.epsilon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2bETgcHHvTP",
        "outputId": "6e3b0210-a632-4ada-9901-d06d218f2c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epsilon =  2.220446049250313e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "üü™ üü™ üü™\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4jZFiqBC3BU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü° 4) Errors in numerical methods\n",
        "\n",
        "## 4-1) Round-off error\n",
        "* Since the computer use a finite number of bits for storing mantissa and exponents of floating-point numbers, not every number can be accurately represented in binary format.\n",
        "* For example, 1.1 cannot be represented exactly with double-precision model. But 0.5 can be represented precisely with double-precision model."
      ],
      "metadata": {
        "id": "lj2YqANkPX8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x: float = 1.1\n",
        "y: float = 0.5\n",
        "print(\"%.17e\" %(x))\n",
        "print(\"%.17e\" %(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhXK58FzQuXt",
        "outputId": "a9a1c39d-58b3-49e7-e7b8-392bea2fdb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10000000000000009e+00\n",
            "5.00000000000000000e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* When a mathematical operation is performed between two numbers, the computer may commit a round-off error."
      ],
      "metadata": {
        "id": "NGyoTO9cSOHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = 5.0e-7\n",
        "l = 5.0e+9\n",
        "print(\"exact value of s: %.17e\" %(s))\n",
        "print(\"exact value of l: %.17e\" %(l))\n",
        "print(\"sum: %.17e\" %(s+l))\n",
        "print(\"subtract: %.17e\" %(l-s))\n",
        "print(\"product: %.17e\" %(s*l))\n",
        "print(\"division: %.17e\" %(s/l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3gtpsxcSm0l",
        "outputId": "655450b3-0ecf-4665-ceb8-aabbeee76d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exact value of s: 4.99999999999999977e-07\n",
            "exact value of l: 5.00000000000000000e+09\n",
            "sum: 5.00000000000000095e+09\n",
            "subtract: 4.99999999999999905e+09\n",
            "product: 2.50000000000000000e+03\n",
            "division: 9.99999999999999979e-17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-2) Truncation error\n",
        "* Truncation error occurs when numerical approximations are used in place of exact mathematical formulas.\n",
        "* For example, consider approximation of the first derivative of a function using finite-difference equation:\n",
        "$$\n",
        "\\frac{df(x)}{dx} ‚âÉ \\frac{Œîf}{Œîx} = \\frac{f(x_2)-f(x_1)}{x_2-x_1} \\tag{8}\n",
        "$$\n",
        "\n",
        "* The above equation does not give us the exact value of the first derivative, but an approximate of it. So, it causes some **error** in the calculations, which we call **truncation error**.\n"
      ],
      "metadata": {
        "id": "M_t1hu9VHdUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def fx(x):\n",
        "  return x*math.sin(x)\n",
        "\n",
        "def dfx(x):\n",
        "  return math.sin(x) + x*math.cos(x)\n",
        "\n",
        "def approximateDf(func, x, eps = 0.01):\n",
        "  return (func(x+eps)-func(x))/eps\n",
        "\n",
        "x = 1.55\n",
        "exact = dfx(x)\n",
        "approximate = approximateDf(fx, x)\n",
        "print(f'df at {x}: exact value is {exact} and approximate value is {approximate}')\n",
        "print(f'Error is {abs(exact-approximate)/exact*100:7.3f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRZr0fnDJvf6",
        "outputId": "54ed87f5-cb30-4256-d31e-e09992609316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df at 1.55: exact value is 1.0320157472841502 and approximate value is 1.0244249065244126\n",
            "Error is   0.736 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Consider Taylor expansions series around $x_i$ with $x_{i+1} = x_i+h$:\n",
        "\n",
        "\n",
        "$$\n",
        "f(x_{i+1}) = f(x_i) + f^{'}(x_i)h+\\frac{f^{\"}(x_i)}{2!}h^2+...+\\frac{f^n(x_i)}{n!}h^n + R_n  \\tag{9}\n",
        "$$\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=1MMZ9Pd8PQrxyKcu8wNzDPwn0dm2zOdEK\" width=\"400\" />\n",
        "</div>"
      ],
      "metadata": {
        "id": "4U0xlLWBMg2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In general, the nth-order Taylor series expansion will be exact for an nth-order polynomial.\n",
        "* For other differentiable and continuous functions, such as exponentials and sinusoids, a finite number of terms will not yield an exact estimate.\n",
        "* Each additional term will\n",
        "contribute some improvement, however slight, to the approximation.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "17fTTlrZ3bQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The reminder is:\n",
        "$$\n",
        "R_n = \\frac{f^{n+1}(\\xi)}{(n+1)!}h^{n+1} \\tag{10}\n",
        "$$\n",
        "* We can re-express it as:\n",
        "$$ R_n = O(h^{n+1})  \\tag{11}\n",
        "$$\n",
        "* Although this notation does not give us the exact value of error (truncation error), but it is useful for judging the change in the error when changing the step size *h*.\n",
        "\n",
        "* if the error is of $O(h^2)$, then halving the step size h, will approximately reduce the error 4 times.\n"
      ],
      "metadata": {
        "id": "eCodnlQj4Wrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùì **Example 3:**\n",
        "Estimate the $f(x) = cos(x)$ at $x = \\pi/6$ using Taylor expansions series at $x = 0$.\n",
        "\n",
        "### üí° Solution\n",
        "We use the Taylor series around $x_i = 0$  with $h =\\pi/6$  and  $f(x_i) = cos(x_i)$. The exact value of function at   $\\pi/6$   is 0.8660254038\n",
        "\n",
        " - With one term of of Taylor series:\n",
        "\n",
        "  $\\begin{aligned} f(\\pi/6) ‚âÉ f(0) = 1\\end{aligned}$\n",
        "  \n",
        "  $\\begin{aligned}\n",
        "  œµ_t = |\\frac{0.86602504-1}{0.86602504}| \\times 100 = 15.47 \\%\n",
        "  \\end{aligned}$\n",
        "\n",
        " - with two terms of Taylor sereis, the second term is added:\n",
        "\n",
        "  $\\begin{aligned} -sin(0)*\\pi/6 = 0\\end{aligned}$\n",
        "  \n",
        "  and the approximate will be 1.\n",
        "\n",
        " - with three terms, the thirs term is added:\n",
        "  \n",
        "  $\\begin{aligned} -cos(0)*(\\pi/6)^2 = -0.13707784\\end{aligned}$\n",
        "\n",
        "  $\\begin{aligned}\n",
        "  f(\\pi/6) ‚âÉ 1 - 0 -0.13707784 = 0.86292216 \\\\\n",
        "  œµ_t = |\\frac{0.86602504-0.86292216}{0.86602504}| \\times 100 = 0.35 \\%\n",
        "  \\end{aligned}$\n"
      ],
      "metadata": {
        "id": "m3NULBTj6Nzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code for Example 3**"
      ],
      "metadata": {
        "id": "Ue2WDe61hK4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def dfx(x , n=0):\n",
        "  if n%2 == 0:\n",
        "    res = math.cos(x)\n",
        "  else:\n",
        "    res = math.sin(x)\n",
        "\n",
        "  e = int((n+1)/2)\n",
        "  return res *math.pow(-1, e)\n",
        "\n",
        "x = 0\n",
        "tol = 0.5\n",
        "h = math.pi/6.0\n",
        "exact = math.cos(math.pi/6.0)\n",
        "approximate = 0\n",
        "\n",
        "for i in range (30):\n",
        "  term = dfx(x,i) * math.pow(h,i)/math.factorial(i)\n",
        "  approximate += term\n",
        "  et = abs(approximate-exact)/exact*100\n",
        "  print(f'{i+1:3d} - function approximate is {approximate:10.8f}'\n",
        "        f' and true error is {et:6.3f} %')\n",
        "  if et <tol :\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NR4D3slnqvz",
        "outputId": "981270fd-f11c-45b2-a550-d4c4af25d366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1 - function approximate is 1.00000000 and true error is 15.470 %\n",
            "  2 - function approximate is 1.00000000 and true error is 15.470 %\n",
            "  3 - function approximate is 0.86292216 and true error is  0.358 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-3) Total error\n",
        "* The *total numerical error* is the summation of the truncation and roundoff errors.\n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=1SLszX-3oYQk5lWzt3FjHIoMYggVMCFop\" width=\"500\" />\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "kAaRVIxEhEhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align = \"center\">\n",
        "üü®üü®üü®\n",
        "</div>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ucfgcwwLm1J8"
      }
    }
  ]
}